{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import models, datasets\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class notMNIST(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.images = data\n",
    "        self.labels = labels\n",
    "\n",
    "        self.transformation = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        img_tensor = self.transformation(img)\n",
    "        y_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        return img_tensor.view(1, 28, 28), y_tensor\n",
    "\n",
    "data = loadmat('data/notMNIST_small.mat')\n",
    "print(data.keys())\n",
    "\n",
    "images = data['images']\n",
    "labels = data['labels']\n",
    "\n",
    "images = [images[:, :, i] for i in range(0, images.shape[2])]\n",
    "images = np.asarray(images)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.4, shuffle=True)\n",
    "\n",
    "train_dataset = notMNIST(x_train, y_train)\n",
    "test_dataset = notMNIST(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        # Input layer: 28*28 neurons (for each pixel in the image)\n",
    "        # First hidden layer: 512 neurons\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        \n",
    "        # Second hidden layer: 256 neurons\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        \n",
    "        # Third hidden layer: 128 neurons\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        \n",
    "        # Output layer: 10 neurons (one for each class A-J)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Activation function: ReLU\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # Flatten the input tensor\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # First convolutional layer: 1 input channel, 32 output channels\n",
    "        # Kernel size: 3x3\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Max pooling with 2x2 window\n",
    "        \n",
    "        # Second convolutional layer: 32 input channels, 64 output channels\n",
    "        # Kernel size: 3x3\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Fully connected layer: 64*7*7 input neurons (from the last convolutional layer)\n",
    "        # 128 output neurons\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        \n",
    "        # Output layer: 128 input neurons, 10 output neurons (one for each class A-J)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Activation function: ReLU\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64*7*7)  # Flatten the tensor\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Call the parent __init__ function\n",
    "        super(BasicCNN, self).__init__()\n",
    "\n",
    "        # First convolutional layer:\n",
    "        # 1 input channel (because the image is grayscale),\n",
    "        # 32 output channels, 3x3 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        \n",
    "        # Second convolutional layer:\n",
    "        # 32 input channels (from the previous layer),\n",
    "        # 64 output channels, 3x3 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        \n",
    "        # Dropout layer to reduce overfitting; drops 25% of nodes\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        \n",
    "        # Another dropout layer, but drops 50% of nodes\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        # First fully connected (dense) layer: \n",
    "        # 9216 input features (from the previous layer after flattening),\n",
    "        # 128 output features\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        \n",
    "        # Second fully connected layer that reduces to 10 outputs (for the 10 classes A-J)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through the first convolutional layer, then apply ReLU activation function\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Pass through the second convolutional layer, then apply ReLU activation\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Apply max pooling with 2x2 window\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Apply first dropout layer\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Pass through the first fully connected layer, then apply ReLU activation\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Apply second dropout layer\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        # Pass through the second fully connected layer\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Apply softmax to get probabilities; return result\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepCNN, self).__init__()\n",
    "        \n",
    "        # Initial convolutional layers are the same as BasicCNN\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "\n",
    "        # Additional deeper convolutional layers\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, 1)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        # Adjusted input features for the fully connected layer based on the deeper architecture\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    # The forward method structure is similar to BasicCNN but has added layers\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShallowCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        \n",
    "        # Only one dropout layer\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Adjusted input features for the single fully connected layer\n",
    "        self.fc1 = nn.Linear(32 * 26 * 26, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the models\n",
    "mlp_model = MLP()\n",
    "cnn_model = DeepCNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss functions and optimizers\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "mlp_optimizer = torch.optim.Adam(mlp_model.parameters(), lr=0.001)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train_model(model, optimizer, criterion, dataloader, epochs=30):\n",
    "    \"\"\"\n",
    "    Train a given model using the specified optimizer and criterion.\n",
    "\n",
    "    Args:\n",
    "    - model: PyTorch model to be trained\n",
    "    - optimizer: Optimizer for updating model parameters\n",
    "    - criterion: Loss function\n",
    "    - dataloader: DataLoader for the training data\n",
    "    - epochs: Number of epochs (default=10)\n",
    "\n",
    "    Returns:\n",
    "    - list of losses per epoch\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.train()  # Set the model to training mode\n",
    "    loss_list = []  # To store the loss per epoch\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in trange(epochs, desc=\"Epochs\"):\n",
    "        # ... [rest of the code remains unchanged]\n",
    "        epoch_loss = 0  # Initialize epoch loss\n",
    "\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Batches\", leave=False):\n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device)\n",
    "            optimizer.zero_grad()  # Clear gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Calculate loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        loss_list.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
    "    model.eval()\n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluate the given model using the specified dataloader.\n",
    "\n",
    "    Args:\n",
    "    - model: Trained PyTorch model\n",
    "    - dataloader: DataLoader for the evaluation data\n",
    "\n",
    "    Returns:\n",
    "    - Accuracy of the model on the evaluation data\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients during evaluation\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Evaluation\", leave=False):\n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device)  # Move inputs and labels to the device and ensure float32 type\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mlp_model.to(device)\n",
    "\n",
    "# Training the MLP model\n",
    "mlp_losses = train_model(mlp_model, mlp_optimizer, criterion, DataLoader(train_dataset, batch_size=64, shuffle=True), epochs=30)\n",
    "\n",
    "# Evaluating the MLP model\n",
    "mlp_accuracy = evaluate_model(mlp_model, DataLoader(test_dataset, batch_size=64))\n",
    "print(f\"MLP Model Accuracy: {mlp_accuracy:.2f}%\")\n",
    "\n",
    "# Assuming cnn_model is defined and moved to the correct device as well:\n",
    "cnn_model.to(device)\n",
    "\n",
    "# Training the CNN model\n",
    "cnn_losses = train_model(cnn_model, cnn_optimizer, criterion, DataLoader(train_dataset, batch_size=64, shuffle=True), epochs=30)\n",
    "\n",
    "# Evaluating the CNN model\n",
    "cnn_accuracy = evaluate_model(cnn_model, DataLoader(test_dataset, batch_size=64))\n",
    "print(f\"CNN Model Accuracy: {cnn_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(mlp_losses, cnn_losses):\n",
    "    # Initialize a new figure for plotting with a specified size.\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot the MLP model's losses in blue.\n",
    "    plt.plot(mlp_losses, label=\"MLP Model\", color='blue')\n",
    "    \n",
    "    # Plot the CNN model's losses in red.\n",
    "    plt.plot(cnn_losses, label=\"CNN Model\", color='red')\n",
    "    \n",
    "    # Title of the plot.\n",
    "    plt.title(\"Training Loss over Epochs\")\n",
    "    \n",
    "    # Labels for the x and y axes.\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    \n",
    "    # Display the legend to differentiate between MLP and CNN.\n",
    "    plt.legend()\n",
    "    \n",
    "    # Display a grid for better readability.\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Show the plot.\n",
    "    plt.show()\n",
    "\n",
    "plot_losses(mlp_losses, cnn_losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filters(layer):\n",
    "    # Extract filter weights from the layer and convert to numpy for visualization.\n",
    "    filters = layer.weight.data.cpu().numpy()\n",
    "    \n",
    "    # Initialize a figure for displaying multiple images.\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Loop through each filter in the layer.\n",
    "    for i in range(filters.shape[0]):\n",
    "        ax = fig.add_subplot(2, filters.shape[0]//2, i+1) # arranging subplots in 2 rows.\n",
    "        \n",
    "        # Display the filter as an image.\n",
    "        ax.imshow(filters[i][0], cmap='gray')\n",
    "        \n",
    "        # Don't show axis for clarity.\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Show all the filter images.\n",
    "    plt.show()\n",
    "\n",
    "# Assuming your CNN model's first layer is named 'conv1'.\n",
    "plot_filters(cnn_model.conv1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_maps(model, input_image):\n",
    "    # Making sure model is in eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Running the image through the first conv layer\n",
    "    feature_maps1 = model.conv1(input_image.unsqueeze(0).float().to(device))\n",
    "    # If you want to visualize after the second conv layer\n",
    "    # feature_maps2 = model.conv2(F.relu(feature_maps1))\n",
    "    \n",
    "    n_feature_maps = feature_maps1.shape[1]\n",
    "    \n",
    "    # Plotting each feature map\n",
    "    for i in range(n_feature_maps):\n",
    "        plt.subplot(8, 8, i+1)  # Assuming a max of 64 feature maps for display\n",
    "        plt.imshow(feature_maps1[0][i].cpu().detach().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Select a random image from the dataset\n",
    "image, _ = test_dataset[5]\n",
    "plt.imshow(image[0], cmap='gray')  # Displaying the selected image\n",
    "plt.show()\n",
    "\n",
    "# Displaying feature maps for the selected image\n",
    "visualize_feature_maps(cnn_model, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def get_all_preds_and_labels(model, dataloader):\n",
    "    # Empty tensors to store all predictions and true labels.\n",
    "    all_preds = torch.tensor([]).to(device)\n",
    "    all_labels = torch.tensor([]).to(device)\n",
    "    \n",
    "    # Loop through the data in the dataloader.\n",
    "    for inputs, labels in dataloader:\n",
    "        # Convert inputs to float32\n",
    "        inputs = inputs.float()\n",
    "        # Move the data to the device (GPU/CPU).\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass to get predictions.\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Get the index (class label) with the maximum score as the prediction.\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Append the batch's predictions and labels to the accumulating tensors.\n",
    "        all_preds = torch.cat((all_preds, preds), dim=0)\n",
    "        all_labels = torch.cat((all_labels, labels), dim=0)\n",
    "    \n",
    "    # Return all predictions and true labels.\n",
    "    return all_preds, all_labels\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def plot_confusion_matrix(all_preds, all_labels):\n",
    "    # Compute the confusion matrix using sklearn's function.\n",
    "    cm = metrics.confusion_matrix(all_labels.cpu(), all_preds.cpu())\n",
    "    \n",
    "    # Define the labels you're using (in this case, it's A-J).\n",
    "    labels = [chr(i) for i in range(ord('A'), ord('J') + 1)]\n",
    "    \n",
    "    # Create the ConfusionMatrixDisplay object.\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    \n",
    "    # Plot the confusion matrix.\n",
    "    cm_display.plot(cmap='Blues')\n",
    "    plt.show()\n",
    "\n",
    "# After training your CNN model\n",
    "cnn_model = cnn_model.float()\n",
    "all_preds, all_labels = get_all_preds_and_labels(cnn_model, DataLoader(test_dataset, batch_size=64))\n",
    "plot_confusion_matrix(all_preds, all_labels)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".zadanie1_pismenka_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
