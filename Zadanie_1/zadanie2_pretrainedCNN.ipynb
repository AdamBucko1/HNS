{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import models, datasets\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "\n",
    "# Hyperparameters\n",
    "N_EPOCHS = 0\n",
    "LEARNING_RATE = 0.0001\n",
    "TEST_SIZE=0.20\n",
    "BATCH_SIZE=128\n",
    "\n",
    "# Transformations for our dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 128x128\n",
    "    transforms.ToTensor(),          # Convert PIL image to PyTorch tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to range [-1, 1] for better training stability\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "root_dir = 'data_zadanie2/'  # Modify this to the path where your image folders (cat, chicken, etc.) are located\n",
    "full_dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "\n",
    "# Splitting the dataset\n",
    "train_size = int((1 - TEST_SIZE) * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained AlexNet model\n",
    "def get_alex_model():\n",
    "    alexnet = models.alexnet(pretrained=True)\n",
    "    num_layers = 0\n",
    "\n",
    "    for param in alexnet.parameters():\n",
    "        param.requires_grad = False\n",
    "        num_layers = num_layers + 1\n",
    "\n",
    "    alexnet.classifier[6] = nn.Linear(4096, 8)  \n",
    "    alexnet.eval()\n",
    "    input_tensor = torch.randn(1, 3, 224, 224)  # Example random input\n",
    "    alexnet(input_tensor)\n",
    "    num_layers\n",
    "\n",
    "    return alexnet\n",
    "\n",
    "def get_vgg16_model():\n",
    "    vgg16 = models.vgg16(pretrained=True)\n",
    "    num_layers = 0\n",
    "\n",
    "    for param in vgg16.features.parameters():\n",
    "        param.requires_grad = False\n",
    "        num_layers = num_layers + 1\n",
    "\n",
    "    num_features = vgg16.classifier[6].in_features\n",
    "    vgg16.classifier[6] = nn.Linear(num_features, 8)  # Modify the output layer for your specific task\n",
    "    vgg16.eval()\n",
    "    input_tensor = torch.randn(1, 3, 224, 224)  # Example random input\n",
    "    vgg16(input_tensor)\n",
    "    \n",
    "    return vgg16\n",
    "\n",
    "def get_resnet18_model():\n",
    "    resnet18 = models.resnet18(pretrained=True)\n",
    "    num_layers = 0\n",
    "\n",
    "    for param in resnet18.parameters():\n",
    "        param.requires_grad = False\n",
    "        num_layers = num_layers + 1\n",
    "\n",
    "    num_features = resnet18.fc.in_features\n",
    "    resnet18.fc = nn.Linear(num_features, 8)  # Modify the output layer for your specific task\n",
    "    resnet18.eval()\n",
    "    input_tensor = torch.randn(1, 3, 224, 224)  # Example random input\n",
    "    resnet18(input_tensor)\n",
    "    \n",
    "    return resnet18\n",
    "\n",
    "\n",
    "def get_mobilenet_model():\n",
    "    mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "    num_layers = 0\n",
    "\n",
    "    for param in mobilenet.parameters():\n",
    "        param.requires_grad = False\n",
    "        num_layers = num_layers + 1\n",
    "\n",
    "    num_features = mobilenet.classifier[1].in_features\n",
    "    mobilenet.classifier[1] = nn.Linear(num_features, 8)  # Modify the output layer for your specific task\n",
    "    mobilenet.eval()\n",
    "    input_tensor = torch.randn(1, 3, 224, 224)  # Example random input\n",
    "    mobilenet(input_tensor)\n",
    "    \n",
    "    return mobilenet\n",
    "\n",
    "step = 16/4\n",
    "step = 26/4\n",
    "step = 62/4\n",
    "step = 158/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluate the given model using the specified dataloader.\n",
    "\n",
    "    Args:\n",
    "    - model: Trained PyTorch model\n",
    "    - dataloader: DataLoader for the evaluation data\n",
    "\n",
    "    Returns:\n",
    "    - Accuracy of the model on the evaluation data\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients during evaluation\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Evaluation\", leave=False):\n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device)  # Move inputs and labels to the device and ensure float32 type\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train_model(model, optimizer, criterion, dataloader, epochs, unfreez, save_name):\n",
    "    \"\"\"\n",
    "    Train a given model using the specified optimizer and criterion.\n",
    "\n",
    "    Args:\n",
    "    - model: PyTorch model to be trained\n",
    "    - optimizer: Optimizer for updating model parameters\n",
    "    - criterion: Loss function\n",
    "    - dataloader: DataLoader for the training data\n",
    "    - epochs: Number of epochs (default=10)\n",
    "\n",
    "    Returns:\n",
    "    - list of losses per epoch\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.train()  # Set the model to training mode\n",
    "    loss_list = []  # To store the loss per epoch\n",
    "    accuracy_list= []\n",
    "    freeze_first_n_layers = 0 \n",
    "    \n",
    "    # Loop over epochs\n",
    "    for epoch in trange(epochs, desc=\"Epochs\"):\n",
    "        # ... [rest of the code remains unchanged]\n",
    "        epoch_loss = 0  # Initialize epoch loss\n",
    "        model.zero_grad()\n",
    "        count = 0\n",
    "\n",
    "        if epoch < 3:\n",
    "            freeze_first_n_layers = freeze_first_n_layers - step\n",
    "        elif epoch < 6:\n",
    "            freeze_first_n_layers = freeze_first_n_layers - 2*step\n",
    "        elif epoch < 9:\n",
    "            freeze_first_n_layers = freeze_first_n_layers - 3*step\n",
    "        elif epoch < 12:\n",
    "           freeze_first_n_layers = freeze_first_n_layers - 4*step\n",
    "\n",
    "        if unfreez:\n",
    "            # unfreeze backbone layers\n",
    "            for param in model.children():\n",
    "                count +=1\n",
    "                if count > freeze_first_n_layers: \n",
    "                    param.requires_grad = True     \n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=\"Batches\", leave=False):\n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device)\n",
    "            optimizer.zero_grad()  # Clear gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Calculate loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        accuracy=evaluate_model(model, DataLoader(test_dataset, batch_size=BATCH_SIZE))\n",
    "        accuracy_list.append(accuracy)\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        loss_list.append(avg_loss)\n",
    "        print(\"Epoch {}, Loss {:.6f}, Accuracy {:.2f}% \".format(epoch, avg_loss, accuracy))\n",
    "\n",
    "    torch.save(model.state_dict(), 'modely_zadanie_2/' + save_name + \".pth\")   \n",
    "    model.eval()\n",
    "    return loss_list,accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"cuda\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training the CNN model\n",
    "cnn_model1 = get_mobilenet_model()\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model1.parameters(), lr=LEARNING_RATE)\n",
    "cnn_model1.to(device)\n",
    "cnn_losses1,cnn_accuracy_list1 = train_model(cnn_model1, cnn_optimizer, criterion, DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True), epochs=N_EPOCHS, unfreez=True, save_name='mobilenet_model_1')\n",
    "# Evaluating the CNN model\n",
    "cnn_accuracy = evaluate_model(cnn_model1, DataLoader(test_dataset, batch_size=BATCH_SIZE))\n",
    "print(f\"CNN Model Accuracy: {cnn_accuracy:.2f}%\")\n",
    "\n",
    "cnn_model2 = get_mobilenet_model()\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model2.parameters(), lr=LEARNING_RATE)\n",
    "cnn_model2.to(device)\n",
    "cnn_losses2,cnn_accuracy_list2 = train_model(cnn_model2, cnn_optimizer, criterion, DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True), epochs=N_EPOCHS, unfreez=False,save_name='mobilenet_model_2')\n",
    "# Evaluating the CNN model\n",
    "cnn_accuracy = evaluate_model(cnn_model2, DataLoader(test_dataset, batch_size=BATCH_SIZE))\n",
    "print(f\"CNN Model Accuracy: {cnn_accuracy:.2f}%\")\n",
    "\n",
    "# Augmentation\n",
    "# Define a custom dataset class for rotated images\n",
    "import random\n",
    "class RotatedImageDataset(Dataset):\n",
    "    def __init__(self, original_dataset, rotate_prob=1):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.rotate_prob = rotate_prob\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.original_dataset[idx]\n",
    "\n",
    "        # Randomly decide whether to rotate the image or not\n",
    "        should_rotate = random.random() < self.rotate_prob\n",
    "\n",
    "        if should_rotate:\n",
    "            # Rotate the image by 90 degrees\n",
    "            image = transforms.functional.rotate(image, 90)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Hyperparameters\n",
    "TEST_SIZE=0.40\n",
    "\n",
    "# Transformations for our dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),          \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to range [-1, 1] for better training stability\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "root_dir = 'data_zadanie2/'  # Modify this to the path where your image folders (cat, chicken, etc.) are located\n",
    "original_dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "\n",
    "augment_data_size = int((1 - 0.6) * len(original_dataset))\n",
    "unused_size = len(original_dataset) - augment_data_size\n",
    "augment_data, unused = random_split(original_dataset, [augment_data_size, unused_size])\n",
    "rotated_dataset = RotatedImageDataset(augment_data, rotate_prob=1)\n",
    "\n",
    "train_size = int((1 - TEST_SIZE) * len(original_dataset))\n",
    "test_size = len(original_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(original_dataset, [train_size, test_size])\n",
    "train_dataset = torch.utils.data.ConcatDataset([train_dataset, rotated_dataset])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "cnn_model3 = get_mobilenet_model()\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model3.parameters(), lr=LEARNING_RATE)\n",
    "cnn_model3.to(device)\n",
    "cnn_losses3,cnn_accuracy_list3 = train_model(cnn_model3, cnn_optimizer, criterion, DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True), epochs=N_EPOCHS, unfreez=True,save_name='mobilenet_model_3')\n",
    "# Evaluating the CNN model\n",
    "cnn_accuracy = evaluate_model(cnn_model3, DataLoader(test_dataset, batch_size=BATCH_SIZE))\n",
    "print(f\"CNN Model Accuracy: {cnn_accuracy:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_accuracy(accuracy_list1,accuracy_list2,accuracy_list3, model_name):\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(accuracy_list1, '-o', label=f'{model_name} Accuracy - Attempt 1')\n",
    "    plt.plot(accuracy_list2, '-o', label=f'{model_name} Accuracy - Attempt 2')\n",
    "    plt.plot(accuracy_list3, '-o', label=f'{model_name} Accuracy - Attempt 3')\n",
    "    plt.title(f'Accuracy Evolution for {model_name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(cnn_losses1,cnn_losses2,cnn_losses3, model_name):\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(cnn_losses1, '-o', label=f'{model_name} Losses  Attempt 1')\n",
    "    plt.plot(cnn_losses2, '-o', label=f'{model_name} Losses  Attempt 2')\n",
    "    plt.plot(cnn_losses3, '-o', label=f'{model_name} Losses  Attempt 3')\n",
    "    plt.title(f'Training Loss evolution for {model_name}')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_filters(layer):\n",
    "    # Extract filter weights from the layer and convert to numpy for visualization.\n",
    "    filters = layer.weight.data.cpu().numpy()\n",
    "    \n",
    "    # Calculate the number of rows and columns for the grid.\n",
    "    num_filters = filters.shape[0]\n",
    "    num_rows = num_columns = int(np.ceil(np.sqrt(num_filters)))\n",
    "    \n",
    "    # Initialize a figure for displaying the filter images.\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(10, 10))\n",
    "    \n",
    "    # Loop through each filter in the layer and display it in the grid.\n",
    "    for i in range(num_filters):\n",
    "        row, col = i // num_columns, i % num_columns\n",
    "        ax = axes[row, col]\n",
    "        ax.imshow(filters[i][0], cmap='gray')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Remove any empty subplots in the grid.\n",
    "    for i in range(num_filters, num_rows * num_columns):\n",
    "        fig.delaxes(axes.flatten()[i])\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filters(layer):\n",
    "    # Extract filter weights from the layer and convert to numpy for visualization.\n",
    "    filters = layer.weight.data.cpu().numpy()\n",
    "    \n",
    "    # Calculate the number of rows and columns for the grid.\n",
    "    num_filters = filters.shape[0]\n",
    "    num_rows = num_columns = int(np.ceil(np.sqrt(num_filters)))\n",
    "    \n",
    "    # Initialize a figure for displaying the filter images.\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(10, 10)\n",
    "                            , gridspec_kw={'wspace': 0.4, 'hspace': 0.4})\n",
    "    \n",
    "    # Loop through each filter in the layer and display it in the grid.\n",
    "    for i in range(num_filters):\n",
    "        row, col = i // num_columns, i % num_columns\n",
    "        ax = axes[row, col]\n",
    "        ax.imshow(filters[i][0], cmap='gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Filter {i}')\n",
    "    \n",
    "    # Remove any empty subplots in the grid.\n",
    "    for i in range(num_filters, num_rows * num_columns):\n",
    "        fig.delaxes(axes.flatten()[i])\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_maps(model, input_image):\n",
    "    # Making sure model is in eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Running the image through the first conv layer\n",
    "    first_conv_layer = model.features[0]\n",
    "    second_conv_layer = model.features[2] \n",
    "\n",
    "    feature_maps1 = first_conv_layer(input_image.unsqueeze(0).float().to(device))\n",
    "    feature_maps2 = second_conv_layer(feature_maps1)\n",
    "    # If you want to visualize after the second conv layer\n",
    "    # feature_maps2 = model.conv2(F.relu(feature_maps1))\n",
    "    \n",
    "    n_feature_maps1 = feature_maps1.shape[1]\n",
    "    n_feature_maps2 = feature_maps2.shape[1]\n",
    "    \n",
    "    # Plotting each feature map\n",
    "    for i in range(n_feature_maps1):\n",
    "        plt.subplot(8, 8, i+1)  # Assuming a max of 64 feature maps for display\n",
    "        plt.imshow(feature_maps1[0][i].cpu().detach().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    for i in range(n_feature_maps2):\n",
    "        plt.subplot(8, 8, i+1)  # Assuming a max of 64 feature maps for display\n",
    "        plt.imshow(feature_maps2[0][i].cpu().detach().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Load the model checkpoint\n",
    "checkpoint = torch.load('modely_zadanie_2/VGG16_model_2.pth')\n",
    "model = get_vgg16_model()\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)   \n",
    "\n",
    "# Select a random image from the dataset\n",
    "image, _ = test_dataset[1]\n",
    "plt.imshow(image[0], cmap='gray')  # Displaying the selected image\n",
    "plt.show()\n",
    "\n",
    "# Displaying feature maps for the selected image\n",
    "# visualize_feature_maps(model, image)\n",
    "plot_filters(model.features[0])\n",
    "plot_filters(model.features[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(cnn_accuracy_list1, cnn_accuracy_list2, cnn_accuracy_list3, \"MobileNet\")\n",
    "plot_losses(cnn_losses1, cnn_losses2, cnn_losses3, \"MobileNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the model checkpoint\n",
    "checkpoint = torch.load('modely_zadanie_2/VGG16_model_3.pth')\n",
    "model = get_vgg16_model()\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def get_all_preds_and_labels(model, dataloader):\n",
    "    # Empty tensors to store all predictions and true labels.\n",
    "    all_preds = torch.tensor([]).to(device)\n",
    "    all_labels = torch.tensor([]).to(device)\n",
    "    \n",
    "    # Loop through the data in the dataloader.\n",
    "    for inputs, labels in dataloader:\n",
    "        # Convert inputs to float32\n",
    "        inputs = inputs.float()\n",
    "        # Move the data to the device (GPU/CPU).\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass to get predictions.\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Get the index (class label) with the maximum score as the prediction.\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Append the batch's predictions and labels to the accumulating tensors.\n",
    "        all_preds = torch.cat((all_preds, preds), dim=0)\n",
    "        all_labels = torch.cat((all_labels, labels), dim=0)\n",
    "    \n",
    "    # Return all predictions and true labels.\n",
    "    return all_preds, all_labels\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def plot_confusion_matrix(all_preds, all_labels):\n",
    "    # Compute the confusion matrix using sklearn's function.\n",
    "    cm = metrics.confusion_matrix(all_labels.cpu(), all_preds.cpu())\n",
    "    \n",
    "    # Define the labels you're using (in this case, it's A-J).\n",
    "    labels = [\"cat\",\"chicken\",\"cow\",\"dog\",\"elephant\",\"horse\",\"sheep\",\"squirrel\"]\n",
    "    \n",
    "    # Create the ConfusionMatrixDisplay object.\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    \n",
    "    # Plot the confusion matrix.\n",
    "    cm_display.plot(cmap='Blues')\n",
    "    plt.show()\n",
    "\n",
    "# After training your CNN model\n",
    "cnn_model = model.float()\n",
    "all_preds, all_labels = get_all_preds_and_labels(cnn_model, DataLoader(test_dataset, batch_size=64))\n",
    "plot_confusion_matrix(all_preds, all_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".zadanie1_pismenka_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
